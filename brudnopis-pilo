---

# 5. Jak to wpływa na rolę developera i architekta

---

## Technologia buduje przewagę konkurencyjną

Ale nie sama technologia.

➡️ **Przewagę buduje ktoś, kto potrafi ją zastosować w systemie i procesie**

Biznes:
- nie wymyśli MCP  
- nie wymyśli agentów  
- nie wymyśli pluginów  
- nie zna ograniczeń LLM  

➡️ **To nie jest ich rola**

---

## Nowa odpowiedzialność po stronie technicznej

Jeśli AI:
- zmienia sposób wytwarzania  
- zmienia tempo dostarczania  
- zmienia architekturę  

➡️ to **developer i architekt** muszą:
- zaproponować rozwiązania  
- ocenić ryzyko  
- ustawić procesy  

---

## Przykład: MCP w e-commerce

Biznes nigdy nie powie:
> „Zbudujmy MCP do produktów”

Bo:
- nie wiedzą, że MCP istnieje  
- nie wiedzą, że LLM może konsumować dane produktowe  
- nie wiedzą, że agent może działać na katalogu  

---

## Kto to zaproponuje?

➡️ **Architekt / senior dev**, który:
- zna MCP  
- rozumie architekturę e-commerce  
- zna ograniczenia LLM (kontekst, latencja, koszty)  

I potrafi powiedzieć:
> „Jeśli wystawimy produkty jako MCP, to:
> - agenty będą mogły je eksplorować
> - support i sales dostaną nowe możliwości
> - skrócimy time-to-value”

---

## To nie jest hype — to decyzja architektoniczna

Architekt musi wiedzieć:
- jak wersjonować MCP  
- jak zabezpieczyć dostęp  
- jak ograniczyć scope danych  
- gdzie MCP ma granice  

➡️ **To jest architektura systemu**, nie demo.

---

## Pluginowość = realna przewaga

AI dramatycznie:
- zwiększa liczbę zmian  
- zwiększa liczbę autorów kodu  
- zwiększa chaos kontekstowy  

➡️ **Pluginowa architektura staje się krytyczna**

---

## Dlaczego pluginowość jest ważniejsza niż wcześniej?

Bo:
- agent nie ogarnia monolitu  
- LLM działa lepiej w małym kontekście  
- mniejszy kontekst = lepsze decyzje  

➡️ Plugin:
- ma jasne API  
- ma ograniczony scope  
- da się testować osobno  

---

## Rola architekta: bronić pluginowości

Nie tylko w kodzie.

Ale w:
- review  
- standardach  
- decyzjach „na szybko”  

Architekt musi umieć powiedzieć:
> „Nie, nie wrzucamy tego do core — to powinien być plugin”

Bo:
- AI przyspiesza złe decyzje tak samo jak dobre

---

## Code review w świecie AI

AI:
- pisze więcej kodu  
- szybciej  
- czasem bez zrozumienia kontekstu  

➡️ **Code review nie może być już tylko stylem i testami**

---

## Nowy cel code review

Chronić:
- architekturę  
- granice kontekstów  
- pluginowość  
- odpowiedzialności modułów  

Pytania w review:
- czy ten kod łamie granice?
- czy agent nie „wciągnął” za dużo?
- czy to da się wyciąć jako plugin?

---

## AI w SDLC — ktoś musi to wdrożyć

AI nie „wchodzi samo” w SDLC.

Ktoś musi:
- zaprojektować onboarding agenta  
- określić gdzie AI może commitować  
- ustawić role: sugestia vs decyzja  
- określić odpowiedzialność człowieka  

➡️ To jest **design procesu**, nie toola.

---

## Onboarding agenta ≠ prompt

To:
- dostęp do repo  
- zakres odpowiedzialności  
- kontekst domenowy  
- zasady eskalacji  

Architekt / senior decyduje:
> „Ten agent:
> - może refaktoryzować pluginy
> - nie może zmieniać core
> - wymaga review człowieka”

---

## FDE: 

tODO
---

## Co się realnie zmienia w roli developera?

Mniej:
- pisania boilerplate  
- ręcznego klepania  

Więcej:
- decyzji architektonicznych  
- pracy na granicach systemu  
- rozumienia całości  

---

## Co się realnie zmienia w roli architekta?

Architekt:
- nie tylko „rysuje diagramy”  
- ale **aktywnie ustawia system pod AI**

Decyduje:
- gdzie AI ma wejść  
- gdzie nie  
- jak chronić system przed chaosem  

---

## Podsumowanie

AI nie zabiera roli developera ani architekta.

AI:
- **podnosi poprzeczkę**

Wygrywają ci, którzy:
- rozumieją architekturę  
- rozumieją SDLC  
- rozumieją ograniczenia AI  
- potrafią zaproponować konkretne rozwiązania

➡️ **To jest miejsce, gdzie buduje się przewagę konkurencyjną**


---

## AI wchodzi w obszary, których wcześniej nie dotykało

Klasycznie:
- kod pisał człowiek  
- decyzje były explicite  
- odpowiedzialność była jasna  

AI:
- generuje zmiany masowo  
- eksploruje system  
- łączy dane, których nikt ręcznie nie łączył  

➡️ **To zmienia model ryzyka**

---

## Problem #6: agent widzi za dużo

Agent:
- ma dostęp do repo  
- ma dostęp do dokumentacji  
- ma dostęp do danych  

Często:
- więcej niż pojedynczy developer  
- więcej niż miałby człowiek na start  

➡️ **Zaczynamy łamać zasadę least privilege**

---

## To nie jest tylko security — to governance

Bo pytania są inne:
- kto zdecydował, że agent ma ten dostęp?
- czy agent może łączyć te dane?
- czy agent „rozumie”, czego nie wolno mu wypuścić?

➡️ **Brakuje decyzji, nie narzędzi**

---

## Klasyczne security nie wystarcza

IAM, role, ACL:
- działają na poziomie systemów  
- nie działają na poziomie *intencji*  

AI:
- nie wykrada danych  
- ale może je **zsyntetyzować**  

➡️ To nowy wektor ryzyka

---

## Problem #7: agent robi „dobrą” rzecz w zły sposób

Przykład:
- agent poprawia bug  
- potrzebuje danych produkcyjnych  
- wyciąga je do promptu  

Technicznie:
- wszystko działa  

Security:
- wyciek kontekstowy  

➡️ **Nikt tego nie zaplanował**

---

## Rozwiązanie: governance na poziomie agentów

Nie:
- „AI policy w Confluence”  

Tylko:
- **architektura agentów**

Decyzje:
- jakie agenty istnieją  
- jaki mają scope  
- z jakich źródeł mogą korzystać  

---

## Agent ≠ człowiek

Człowiek:
- ma intuicję  
- ma strach  
- ma kontekst organizacyjny  

Agent:
- wykona zadanie  
- jeśli nie ma zakazu — pójdzie dalej  

➡️ Governance musi być **jawne i techniczne**

---

## Problem #8: brak audytu decyzji AI

Po incydencie:
- nie wiemy, który agent  
- nie wiemy, na jakich danych  
- nie wiemy, dlaczego  

Logi:
- nie wystarczą  

➡️ **Brakuje audytu decyzyjnego**

---

## Rozwiązanie: decyzje AI jako artefakty

Każda istotna akcja agenta:
- jest zapisana  
- ma kontekst  
- ma uzasadnienie  

Np.:
- „dlaczego zmieniłem ten kod”
- „jakie źródła wykorzystałem”
- „jakie reguły governance obowiązywały”

➡️ To jest **nowy rodzaj audytu**

---

## Rola architekta w security & governance

Architekt:
- projektuje granice agentów  
- definiuje „strefy zakazane”  
- decyduje, gdzie AI nie wchodzi  

Nie deleguje tego:
- na security  
- na compliance  

Bo:
➡️ **to jest część architektury systemu**

---

## Rola developera

Developer:
- wie, gdzie AI pomaga  
- wie, gdzie AI jest ryzykiem  

Jego zadanie:
- zgłosić niebezpieczne miejsca  
- opisać nieformalne zasady  
- przekazać wiedzę agentom  

➡️ Governance wyrasta z praktyki, nie z dokumentów

---

## Problem #9: Shadow AI wraca tylnymi drzwiami

Jeśli:
- oficjalne AI jest zbyt ograniczone  
- governance jest oderwane od realiów  

Zespół:
- użyje własnych narzędzi  
- obejdzie proces  
- wróci chaos  

➡️ Governance, które blokuje — przegrywa

---

## Dobre governance działa „w tle”

Nie przeszkadza:
- w codziennej pracy  
- w review  
- w eksploracji  

Ale:
- reaguje, gdy zbliżasz się do granicy  
- zatrzymuje, gdy trzeba  

➡️ Jak dobre guardrails, nie mur

---

## Podsumowanie: security i governance w świecie AI

To nie jest:
- checkbox  
- polityka  
- PDF  

To jest:
- **świadome projektowanie ról agentów**
- **jawne granice dostępu**
- **audyt decyzji, nie tylko akcji**
- **architekt w pętli decyzyjnej**

---

## Ostateczna przewaga

Organizacje, które:
- włączą AI bez governance → przyspieszą chaos  
- włączą governance bez zrozumienia AI → zablokują zespoły  

Wygrywają te, które:
➡️ **zaprojektują AI jak część systemu**

To jest trudne.  
Dlatego jest przewagą.


---

## Spec-driven zamiast „AI pisze kod”

AI:
- potrafi zmieniać kod
- nie rozumie transakcji
- nie rozumie konsekwencji biznesowych

➡️ Dlatego potrzebujemy **spec-driven podejścia**

---

## Co to znaczy „spec-driven”?

Spec:
- nie opisuje jak coś działa
- opisuje **kiedy zmiana jest poprawna, a kiedy nie**

To nie jest dokumentacja.
To są **reguły systemu**.


---

## Problem z AI

AI widzi:
- pliki
- funkcje
- testy

Nie widzi:
- że te zmiany muszą wydarzyć się razem
- że stan pośredni jest nieakceptowalny
- że rollback jest drogi

➡️ AI idealnie łamie agregaty

---

## Przykład (intuicyjny)

Zmiana:
- statusu zamówienia
- płatności
- rezerwacji stocku

Technicznie:
- trzy różne miejsca

Biznesowo:
- **jedna transakcja**

➡️ To jest agregat

---

## Spec agregatu (minimalna)

Nie piszemy elaboratów.

Spec mówi:
- co MUSI zmienić się razem
- czego NIE WOLNO zmienić osobno
- jaki stan jest biznesowo niepoprawny

To wystarczy.

---


## Po co ta spec?

Bo:
- testy tego nie wyrażą
- typy tego nie złapią
- AI tego nie zgadnie

Spec:
➡️ przenosi wiedzę architektoniczną do systemu

---

## Spec → agent

Agent w code review:
- nie sprawdza „czy działa”
- sprawdza „czy nie rozcięto agregatu”

> „Ta zmiana dotyka tylko części transakcji”

➡️ Guardrail, nie automat

---

## Co tu robi architekt?

Architekt:
- identyfikuje agregaty
- zapisuje ich reguły
- decyduje gdzie AI może działać
- gdzie musi się zatrzymać

To nie jest governance.
To jest **architektura systemu**.

---


➡️ Biznes rozumie koszt i ryzyko.

---

## Podsumowanie

Spec-driven:
- nie spowalnia
- skraca feedback loop
- pozwala używać AI bez chaosu


Kto to rozumie:
➡️ realnie buduje przewagę konkurencyjną

